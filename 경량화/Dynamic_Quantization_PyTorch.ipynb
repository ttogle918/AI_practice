{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dynamic_Quantization_PyTorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPQBNJSucPEqfNHa6rBMcQU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttogle918/AI_practice/blob/main/%EA%B2%BD%EB%9F%89%ED%99%94/Dynamic_Quantization_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dynamic Quantization(양자화) 튜토리얼 따라하기\n",
        "[(베타) LSTM 기반 단어 단위 언어 모델의 동적 양자화, PyTorch 튜토리얼](https://tutorials.pytorch.kr/advanced/dynamic_quantization_tutorial.html)\n",
        "\n",
        "양자화는 float타입인 Tensor 가중치와 활성화 함수를 int형으로 변환하여 모델의 크기를 줄이고 추론(test) 속도를 높이는 방법이다.\n",
        "\n",
        "- float -> int\n",
        "- 모델의 크기 ↓, 속도 ↑(빠르게), 성능(loss)은 그대로"
      ],
      "metadata": {
        "id": "g1RIbHmXwIMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext torchdata "
      ],
      "metadata": {
        "id": "dmfIMBi1iLWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mOk305QSgywa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from io import open\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchtext.datasets import WikiText2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, ntoken, ninp, nhid, nlayers, dropout=0.5):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.encoder = nn.Embedding(ntoken, ninp)\n",
        "        self.rnn = nn.LSTM(ninp, nhid, nlayers, dropout=dropout)\n",
        "        self.decoder = nn.Linear(nhid, ntoken)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "        self.nhid = nhid\n",
        "        self.nlayers = nlayers\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        emb = self.drop(self.encoder(input))\n",
        "        output, hidden = self.rnn(emb, hidden)\n",
        "        output = self.drop(output)\n",
        "        decoded = self.decoder(output)\n",
        "        return decoded, hidden\n",
        "\n",
        "    def init_hidden(self, bsz):\n",
        "        weight = next(self.parameters())\n",
        "        return (weight.new_zeros(self.nlayers, bsz, self.nhid),\n",
        "                weight.new_zeros(self.nlayers, bsz, self.nhid))"
      ],
      "metadata": {
        "id": "GaBdUOCtg-gI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "[ShardingFilterIterDataPipe 문서](https://www.ccoderun.ca/programming/doxygen/pytorch/classtorch_1_1utils_1_1data_1_1datapipes_1_1iter_1_1grouping_1_1ShardingFilterIterDataPipe.html#a671003f20672f8f6b74d2c03394ed685)"
      ],
      "metadata": {
        "id": "k6uvzyf1hCAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = WikiText2(root='.data', split=('train', 'valid', 'test'))\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypfQ6ChkhmTs",
        "outputId": "a935e13e-cee4-4bc5-eecf-5548e8455ecb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(ShardingFilterIterDataPipe,\n",
              " ShardingFilterIterDataPipe,\n",
              " ShardingFilterIterDataPipe)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, n in enumerate(dataset[0]) :\n",
        "  print(n)\n",
        "  if i == 10 :\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sXOuALYknGC",
        "outputId": "d0ce16dd-88ee-4fb9-9d0d-24f3143a07d6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "\n",
            " = Valkyria Chronicles III = \n",
            "\n",
            " \n",
            "\n",
            " Senjō no Valkyria 3 : <unk> Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . <unk> the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" <unk> Raven \" . \n",
            "\n",
            " The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more <unk> for series newcomers . Character designer <unk> Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n . \n",
            "\n",
            " It met with positive sales in Japan , and was praised by both Japanese and western critics . After release , it received downloadable content , along with an expanded edition in November of that year . It was also adapted into manga and an original video animation series . Due to low sales of Valkyria Chronicles II , Valkyria Chronicles III was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 . Media.Vision would return to the franchise with the development of Valkyria : Azure Revolution for the PlayStation 4 . \n",
            "\n",
            " \n",
            "\n",
            " = = Gameplay = = \n",
            "\n",
            " \n",
            "\n",
            " As with previous <unk> Chronicles games , Valkyria Chronicles III is a tactical role @-@ playing game where players take control of a military unit and take part in missions against enemy forces . Stories are told through comic book @-@ like panels with animated character portraits , with characters speaking partially through voiced speech bubbles and partially through <unk> text . The player progresses through a series of linear missions , gradually unlocked as maps that can be freely <unk> through and replayed as they are unlocked . The route to each story location on the map varies depending on an individual player 's approach : when one option is selected , the other is sealed off to the player . Outside missions , the player characters rest in a camp , where units can be customized and character growth occurs . Alongside the main story missions are character @-@ specific sub missions relating to different squad members . After the game 's completion , additional episodes are unlocked , some of them having a higher difficulty than those found in the rest of the game . There are also love simulation elements related to the game 's two main <unk> , although they take a very minor role . \n",
            "\n",
            " The game 's battle system , the <unk> system , is carried over directly from <unk> Chronicles . During missions , players select each unit using a top @-@ down perspective of the battlefield map : once a character is selected , the player moves the character around the battlefield in third @-@ person . A character can only act once per @-@ turn , but characters can be granted multiple turns at the expense of other characters ' turns . Each character has a field and distance of movement limited by their Action <unk> . Up to nine characters can be assigned to a single mission . During gameplay , characters will call out if something happens to them , such as their health points ( HP ) getting low or being knocked out by enemy attacks . Each character has specific \" Potentials \" , skills unique to each character . They are divided into \" Personal Potential \" , which are innate skills that remain unaltered unless otherwise dictated by the story and can either help or impede a character , and \" Battle Potentials \" , which are grown throughout the game and always grant <unk> to a character . To learn Battle Potentials , each character has a unique \" Masters Table \" , a grid @-@ based skill table that can be used to acquire and link different skills . Characters also have Special <unk> that grant them temporary <unk> on the battlefield : Kurt can activate \" Direct Command \" and move around the battlefield without <unk> his Action Point gauge , the character <unk> can shift into her \" Valkyria Form \" and become <unk> , while Imca can target multiple enemy units with her heavy weapon . \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Dictionary(object):\n",
        "    def __init__(self):\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = []\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2idx:\n",
        "            self.idx2word.append(word)\n",
        "            self.word2idx[word] = len(self.idx2word) - 1\n",
        "        return self.word2idx[word]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx2word)\n",
        "\n",
        "\n",
        "class Corpus(object):\n",
        "    def __init__(self, dataset):\n",
        "        self.dictionary = Dictionary()\n",
        "        self.train = self.tokenize(dataset[0])\n",
        "        self.valid = self.tokenize(dataset[1])\n",
        "        self.test = self.tokenize(dataset[2])\n",
        "\n",
        "    def tokenize(self, dataset):\n",
        "        \"\"\"텍스트 파일 토큰화\"\"\"\n",
        "        # 사전에 단어 추가\n",
        "        for line in dataset:\n",
        "            words = line.split() + ['<eos>']\n",
        "            for word in words:\n",
        "                self.dictionary.add_word(word)\n",
        "\n",
        "        # 파일 내용 토큰화\n",
        "        idss = []\n",
        "        for line in dataset:\n",
        "            words = line.split() + ['<eos>']\n",
        "            ids = []\n",
        "            for word in words:\n",
        "                ids.append(self.dictionary.word2idx[word])\n",
        "            idss.append(torch.tensor(ids).type(torch.int64))\n",
        "        ids = torch.cat(idss)\n",
        "\n",
        "        return ids\n",
        "\n",
        "corpus = Corpus(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0yZml4qhAM0",
        "outputId": "3bde0c18-c30b-4001-8597-6b5d57c71493"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/datapipes/iter/combining.py:249: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
            "  \"the buffer and each child DataPipe will read from the start again.\", UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus.train, corpus.dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0PLq7wCm841",
        "outputId": "afa9ba82-05a1-41aa-bdf1-a917f77cda46"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0,  1,  2,  ..., 15,  0,  0]),\n",
              " <__main__.Dictionary at 0x7fde527d0710>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "예제에서는 사전학습된 모델을 불러와서 파라미터 저장을 했지만, loss가 같은지, time이 줄어들었는지, Size(저장될 용량)이 줄었는지 확인하기 위한 양자화 예제이기 때문에 그렇게하지 않았다. "
      ],
      "metadata": {
        "id": "jU30E7EAhEs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ntokens = len(corpus.dictionary)\n",
        "\n",
        "model = LSTMModel(\n",
        "    ntoken = ntokens,\n",
        "    ninp = 768,\n",
        "    nhid = 256,\n",
        "    nlayers = 5,\n",
        ")\n",
        "\n",
        "model.eval()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvLc9YvXhDkd",
        "outputId": "b38695dc-2024-4511-f586-6c7ea7f43aa0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTMModel(\n",
            "  (drop): Dropout(p=0.5, inplace=False)\n",
            "  (encoder): Embedding(33278, 768)\n",
            "  (rnn): LSTM(768, 256, num_layers=5, dropout=0.5)\n",
            "  (decoder): Linear(in_features=256, out_features=33278, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ = torch.randint(ntokens, (1, 1), dtype=torch.long)\n",
        "hidden = model.init_hidden(1)\n",
        "temperature = 1.0\n",
        "num_words = 1000\n",
        "\n",
        "with open('/out.txt', 'w') as outf:\n",
        "    with torch.no_grad():  # 기록을 추적하지 않습니다.\n",
        "        for i in range(num_words):\n",
        "            output, hidden = model(input_, hidden)\n",
        "            word_weights = output.squeeze().div(temperature).exp().cpu()\n",
        "            word_idx = torch.multinomial(word_weights, 1)[0]\n",
        "            input_.fill_(word_idx)\n",
        "\n",
        "            word = corpus.dictionary.idx2word[word_idx]\n",
        "\n",
        "            outf.write(str(word.encode('utf-8')) + ('\\n' if i % 20 == 19 else ' '))\n",
        "\n",
        "            if i % 100 == 0:\n",
        "                print('| Generated {}/{} words'.format(i, 1000))\n",
        "\n",
        "with open('/out.txt', 'r') as outf:\n",
        "    all_output = outf.read()\n",
        "    print(all_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrZY5n0qnTMh",
        "outputId": "bfc9eefa-eafb-4133-b21b-2762f57b590b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Generated 0/1000 words\n",
            "| Generated 100/1000 words\n",
            "| Generated 200/1000 words\n",
            "| Generated 300/1000 words\n",
            "| Generated 400/1000 words\n",
            "| Generated 500/1000 words\n",
            "| Generated 600/1000 words\n",
            "| Generated 700/1000 words\n",
            "| Generated 800/1000 words\n",
            "| Generated 900/1000 words\n",
            "b'straw' b'Promise' b'Disaster' b'incoherent' b'Gravity' b'Alton' b'Scholarship' b'trout' b'clearances' b'shirts' b'170' b'550' b'Levy' b'eclipse' b'exploration' b'elders' b'Tr\\xc3\\xa4umerei' b'creating' b'Facelift' b'sustaining'\n",
            "b'Bend' b'faintest' b'Sub' b'Stent' b'spacecraft' b'albedo' b'Monmouthshire' b'audiobook' b'Lion' b'MSF' b'barrows' b'slightest' b'religions' b'35th' b'sings' b'Humphrey' b'Relief' b'outraged' b'Havelange' b'hp'\n",
            "b'mortar' b'naya' b'invade' b'graphite' b'vessels' b'devil' b'LP' b'Sussex' b'fittoni' b'go' b'assassinate' b'Sami' b'sits' b'Cabrera' b'chloride' b'Mets' b'Accolades' b'guardian' b'hairstyle' b'appointments'\n",
            "b'Acting' b'Trinsey' b'intervene' b'respiratory' b'armed' b'globe' b'usurpers' b'positive' b'1012' b'Choral' b'server' b'staged' b'Cabrera' b'Stockwell' b'Interior' b'diverting' b'cabins' b'Bed' b'shining' b'commercial'\n",
            "b'adapt' b'Saving' b'ITCZ' b'author' b'price' b'Rush' b'tables' b'wicked' b'Splash' b'escalating' b'Nassau' b'Ethiopia' b'tone' b'Israel' b'booty' b'codenamed' b'limb' b'Imbudo' b'negotiated' b'ousted'\n",
            "b'\\xe2\\x99\\xad' b'Cavalcade' b'encounter' b'978' b'penannular' b'MIT' b'percent' b'supplement' b'europaeus' b'Edgeworth' b'rationale' b'experiment' b'succeed' b'Nix' b'eat' b'1903' b'und' b'1569' b'aspired' b'tea'\n",
            "b'autonomously' b'Amendment' b'Point' b'PCG' b'Rapidly' b'cinematic' b'riflemen' b'rotator' b'oxen' b'Di\\xe1\\xbb\\x87m' b'accident' b'18-' b'Us' b'transmitted' b'perch' b'ribosomal' b'eligible' b'Head' b'continuing' b'President'\n",
            "b'diminishing' b'Ellie' b'equated' b'Prakash' b'showcases' b'Interscope' b'Portuguese' b'anesthesia' b'blocked' b'loggers' b'pumas' b'quell' b'architects' b'hadn' b'rescind' b'inauguration' b'Croton' b'aim' b'The' b'Swansea'\n",
            "b'lambs' b'joint' b'precognition' b'Banaadir' b'extract' b'Tobacco' b'powerhouse' b'thank' b'world' b'levy' b'entrepreneur' b'439' b'defined' b'has' b'solicitor' b'headquartered' b'foals' b'menacing' b'Others' b'Paste'\n",
            "b'Bowman' b'Richdale' b'Werner' b'Rita' b'ICP' b'Tsubaki' b'mantelli' b'Tears' b'girl' b'Hadji' b'dormitory' b'autopsy' b'metallicity' b'Narvik' b'galleries' b'unpredictable' b'proph\\xc3\\xa8te' b'its' b'us' b'shadowed'\n",
            "b'Bringin' b'doubling' b'clamp' b'unwillingness' b'Dreamworld' b'1819' b'renewing' b'layout' b'frames' b'FAA' b'absolutist' b'seclusion' b'692' b'Lyon' b'paradigm' b'registered' b'Farr' b'Arromanches' b'acquiring' b'Attacks'\n",
            "b'raises' b'Pier' b'ecstasy' b'tracery' b'8E' b'dimensions' b'Larrabee' b'copious' b'dynastic' b'August' b'Hamersley' b'Occupation' b'evacuate' b'phones' b'FreeStyleGames' b'bestselling' b'Saudi' b'WCA' b'autonomously' b'Taneytown'\n",
            "b'Crimint' b'moulds' b'front' b'Jaguar' b'Mint' b'Dorian' b'provoking' b'onwards' b'drawn' b'Hilo' b'Rothschilds' b'Static' b'FC' b'architects' b'zombies' b'appoints' b'WNWBL' b'Aurora' b'unprofitable' b'Cort\\xc3\\xa9s'\n",
            "b'Hibiscus' b'Krajowa' b'However' b'renovate' b'overcrowding' b'Plain' b'isotope' b'Tunisia' b'dockyards' b'pieces' b'Candidate' b'viviparous' b'game' b'meters' b'hardened' b'complications' b'points' b'sustained' b'eldest' b'Web'\n",
            "b'pressure' b'tropical' b'spans' b'possess' b'Resolution' b'expresses' b'fluency' b'fueled' b'qui' b'hun' b'Editor' b'excels' b'must' b'Modern' b'1809' b'para' b'Fearless' b'Naraharitirtha' b'anticoagulant' b'Opening'\n",
            "b'Shiban' b'witnessing' b'Tsubame' b'aides' b'toilets' b'Barghash' b'Dress' b'commercial' b'sentiment' b'roamed' b'Ry\\xc5\\xabnosuke' b'winters' b'micro' b'Koh' b'Form' b'Boletus' b'Ceres' b'Dhien' b'cater' b'stylistic'\n",
            "b'Casablanca' b'aged' b'belongings' b'numeric' b'salaried' b'broth' b'narrowed' b'Patty' b'touchdowns' b'Toys' b'Huizong' b'826' b'confrontation' b'Ticonderoga' b'legitimate' b'stray' b'take' b'incursion' b'Beaver' b'Pipe'\n",
            "b'residue' b'smaller' b'1052' b'recognition' b'resin' b'specifies' b'USDA' b'reserving' b'Charlie' b'refining' b'Zionism' b'kitchens' b'minefields' b'Ypres' b'Region' b'Southern' b'Gross' b'Renault' b'\\xe1\\x83\\xaa' b'Dirt'\n",
            "b'Lite' b'Named' b'edicts' b'proprietors' b'Innocent' b'lamins' b'D\\xc3\\xbcsseldorf' b'Keeper' b'Heginbotham' b'puddle' b'shortages' b'Lionel' b'Rollefson' b'shoulders' b'Throckmorton' b'leg' b'morphology' b'handled' b'apron' b'oval'\n",
            "b'vengeful' b'\\xe3\\x82\\xb9\\xe3\\x83\\x88\\xe3\\x83\\x83\\xe3\\x83\\x97' b'Antilles' b'Mandarin' b'ceratopsians' b'photographic' b'Astronomers' b'asci' b\"'azzam\" b'Release' b'Mifflin' b'Sisko' b'Marlon' b'livelihood' b'D.J.' b'senator' b'surplus' b'ferrying' b'Widely' b'Hoshi'\n",
            "b'bait' b'Purana' b'Jacksonville' b'symbolism' b'Kuala' b'harbours' b'Canucks' b'Mamluk' b'genealogy' b'83' b'Infantry' b'Amiga' b'issues' b'disobey' b'Enuff' b'turnovers' b'Weekend' b'Drive' b'Advancement' b'Bate'\n",
            "b'totalitarian' b'1884' b'victor' b'Croatian' b'staged' b'bestow' b'teaching' b'score' b'artificially' b'barn' b'discrete' b'jewellery' b'Introduced' b'recognition' b'Row' b'mounds' b'U.S.' b'Brian' b'Subsequently' b'Bethesda'\n",
            "b'recovers' b'wave' b'came' b'expansive' b'Junyi' b'reelected' b'Puzzle' b'lasting' b'bases' b'defeats' b'level' b'Lakes' b'transmitted' b'undistinguished' b'helpful' b'brigades' b'shine' b'Bradstreet' b'fairy' b'blisters'\n",
            "b'League' b'addicted' b'dwarfs' b'Corps' b'relayed' b'did' b'Shorter' b'Jim' b'telecommunication' b'Paraguay' b'markings' b'neighbour' b'accepted' b'weather' b'send' b'pots' b'Zongwang' b'Mennonite' b'embattled' b'Honolulu'\n",
            "b'planning' b'must' b'leverage' b'themselves' b'Garc\\xc3\\xada' b'Mennonite' b'blocks' b'120' b'cystidia' b'Gaurav' b'1887' b'reigned' b'imagery' b'CD' b'intestines' b'1002' b'dislike' b'Nicaea' b'Subsequently' b'Symphonic'\n",
            "b'obtaining' b'kisses' b'Ely' b'2D' b'outlaw' b'molecule' b'Allu' b'selling' b'choruses' b'Beattie' b'horsemen' b'Ferry' b'countenance' b'exemplifies' b'Naidu' b'affray' b'Admiralty' b'Boletinellus' b'pseudoephedrine' b'organelles'\n",
            "b'rubbed' b'Bramall' b'grasses' b'Teenage' b'expertise' b'1789' b'dredges' b'Boston' b'Prey' b'Chasmosaurus' b'Caldwell' b'unaltered' b'gets' b'Living' b'good' b'Nettles' b'DRS' b'superb' b'seized' b'closed'\n",
            "b'attracted' b'workload' b'presentation' b'Style' b'cyclogenesis' b'impartiality' b'fourteenth' b'Graphic' b'viable' b'Outside' b'Emmett' b'alive' b'agent' b'wins' b'narrates' b'7th' b'lumber' b'Trails' b'fumbles' b'elevation'\n",
            "b'brightly' b'DLC' b'immigrants' b'preferred' b'Street' b'Inquisition' b'Damage' b'bettered' b'\\xc3\\x86lfric' b'Hart' b'ritualistic' b'learns' b'worrisome' b'1957' b'insemination' b'vocational' b'eradicated' b'solos' b'persisted' b'Siti'\n",
            "b'unjust' b'Grave' b'recurring' b'Vogt' b'trajectory' b'wrote' b'mosques' b'minimize' b'atop' b'downloadable' b'805' b'scrutiny' b'reunite' b'Taste' b'1126' b'driven' b'Falloppio' b'McGlashan' b'downturn' b'artillery'\n",
            "b'educate' b'europaeus' b'terminated' b'1703' b'Traveling' b'Cisski' b'loverboy' b'Laborintus' b'albinism' b'pigs' b'Historian' b'Tucker' b'sucks' b'!' b'replenish' b'Isesi' b'Benadir' b'Mw' b'origin' b'Aaron'\n",
            "b'Bent' b'lyrical' b'diable' b'libel' b'capsule' b'Mushroom' b'LP' b'Salford' b'forebears' b'responsibilities' b'Mask' b'Turing' b'rejects' b'ravaged' b'midrange' b'Metropolis' b'Poles' b'expressing' b'pipes' b'claimant'\n",
            "b'USDA' b'readiness' b'affect' b'Honor' b'rural' b'exaggerated' b'deficient' b'Minster' b'Prelude' b'fuse' b'remain' b'concerto' b'graphic' b'orders' b'perversion' b'boarding' b'libretto' b'Massacre' b'Lindsey' b'Gale'\n",
            "b\"'\" b'pupils' b'Marg' b'kiosk' b'Is' b'archaeologist' b'Khmer' b'stations' b'familial' b'Vision' b'vicar' b'Calamity' b'Bree' b'Bon' b'thick' b'maskrays' b'elements' b'lounges' b'Hot' b'surmounted'\n",
            "b'Pryce' b'poetry' b'Odriozola' b'Kazakhstan' b'envy' b'assert' b'Nasrallah' b'encounters' b'fly' b'Popular' b'suitably' b'Sutil' b'dredges' b'fur' b'Moffat' b'Membrane' b'UFO' b'Urania' b'Aerial' b'counterattacks'\n",
            "b'buildings' b'dependency' b'chromosomal' b'Beyonc\\xc3\\xa9' b'Often' b'prow' b'replay' b'God' b'Fortress' b'seldom' b'Ingvald' b'78' b'Hellenistic' b'Monster' b'guess' b'related' b'governor' b'basal' b'physics' b'Murdoch'\n",
            "b'Continent' b'consequent' b'Jet' b'Dhien' b'Waters' b'pavement' b'Oh' b'Miller' b'159' b'Korea' b'Henrik' b'demonstrators' b'appropriate' b'dials' b'ties' b'breached' b'Simtek' b'arrests' b'intercity' b'patient'\n",
            "b'Midwest' b'household' b'Pasha' b'Guildenstern' b'dispersed' b'subcontinent' b'granting' b'Cowan' b'Adams' b'1797' b'solutions' b'dupatta' b'strumming' b'Caged' b'comburendo' b'Legal' b'scaffolding' b'Xingyi' b'permitted' b'nearest'\n",
            "b'Amie' b'beaches' b'moor' b'atmospheric' b'wasps' b'Crew' b'renders' b'Webberville' b'Boletus' b'Aikens' b'hampering' b'dwarfs' b'Selected' b'Air' b'absolutism' b'acquiring' b'fighters' b'Ossetian' b'Excavation' b'emergence'\n",
            "b'Mie' b'implications' b'Dasyatis' b'Worthington' b'garnered' b'Sheriff' b'Cutting' b'Pollard' b'simulators' b'amounts' b'Rc8' b'alphabets' b'Prize' b'1984' b'epigenetic' b'vs.' b'This' b'West' b'lupus' b'flies'\n",
            "b'Coastal' b'Parrot' b'encourages' b'Pemba' b'snowberry' b'Paul' b'Triumph' b'trusted' b'Dictator' b'Theakston' b'\\xe1\\x83\\xa3' b'platinum' b'interact' b'unharmed' b'rainfall' b'K7' b'Colonial' b'filed' b'courtly' b'featured'\n",
            "b'eyebrows' b'entrant' b'Diana' b'Havers' b'gene' b'MDT' b'Bode' b'prowess' b'Chants' b'Likewise' b'masjid' b'black' b'Meredith' b'surround' b'disrespect' b'fancy' b'passion' b'Fat' b'magnetosphere' b'San'\n",
            "b'sawgrass' b'Bodashtart' b'Manchester' b'Sveshnikov' b'weakens' b'appear' b'reacted' b'ornithologist' b'disasters' b'Weir' b'Philosophy' b'Topping' b'penance' b'tissue' b'beachfront' b'snurposomes' b'Trey' b'recommendations' b'Abbey' b'Merritt'\n",
            "b'Gaboon' b'insurgents' b'meat' b'critically' b'withdrawing' b'Hague' b'Slash' b'Tramp' b'Mako' b'Penguins' b'Indigenous' b'everyday' b'ceramic' b'Genghis' b'Located' b'shelter' b'Portis' b'@-@' b'spare' b'fantasies'\n",
            "b'512' b'Bracknell' b'marching' b'mph' b'reorganize' b'agarics' b'formats' b'1764' b'obstacle' b'parallax' b'Strategy' b'Fork' b'BPI' b'ignores' b'Classification' b'airstrikes' b'965' b'gracile' b'Ayyubids' b'Richmond'\n",
            "b'Isaiah' b'Identity' b'garde' b'teller' b'Malawi' b'defend' b'witness' b'freelance' b'Chennselaig' b'spoiled' b'Hernia' b'looking' b'Adult' b'chemical' b'Road' b'velvet' b'detonation' b'envelope' b'Development' b'Garland'\n",
            "b'1826' b'roof' b'Lambourn' b'Pompeii' b'certified' b'Troms\\xc3\\xb8' b'scientist' b'276' b'disadvantaged' b'Examples' b'ulama' b'List' b'Haddock' b'Ambroise' b'hydride' b'judgment' b'Veblen' b'Kokury\\xc5\\xab' b'Gedney' b'disrespect'\n",
            "b'approve' b'Churrigueresque' b'ACC' b'Trenchard' b'Naruhod\\xc5\\x8d' b'race' b'Communists' b'guild' b'comb' b'incorporated' b'restart' b'deadlines' b'ploy' b'over' b'annoyed' b'provide' b'wish' b'Sir' b'Card' b'Burt'\n",
            "b'fault' b'accessing' b'Deakin' b'Wofford' b'accuracy' b'Daly' b'drum' b'Lumber' b'adolescent' b'championships' b'undifferentiated' b'2016' b'sacking' b'thorns' b'352nd' b'Shabelle' b'89' b'millions' b'sealed' b'examines'\n",
            "b'strident' b'07' b'ease' b'universal' b'tournament' b'Frankfurt' b'1909' b'Durrant' b'programmable' b'Agricultural' b'identification' b'Sycaminon' b'Graeme' b'tombstone' b'Gilii' b'Crombie' b'viewed' b'Nights' b'risk' b'shipyard'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# helper 함수를 정의"
      ],
      "metadata": {
        "id": "wWpaVi08yztl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bptt = 25\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "eval_batch_size = 1\n",
        "\n",
        "# 테스트 데이터셋 만들기\n",
        "def batchify(data, bsz):\n",
        "    # 데이터셋을 bsz 부분으로 얼마나 깔끔하게 나눌 수 있는지 계산합니다.\n",
        "    nbatch = data.size(0) // bsz\n",
        "    # 깔끔하게 맞지 않는 추가적인 부분(나머지들)을 잘라냅니다.\n",
        "    data = data.narrow(0, 0, nbatch * bsz)\n",
        "    # 데이터에 대하여 bsz 배치들로 동등하게 나눕니다.\n",
        "    return data.view(bsz, -1).t().contiguous()\n",
        "\n",
        "test_data = batchify(corpus.test, eval_batch_size)\n",
        "\n",
        "# 평가 함수들\n",
        "def get_batch(source, i):\n",
        "    seq_len = min(bptt, len(source) - 1 - i)\n",
        "    data = source[i:i+seq_len]\n",
        "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
        "    return data, target\n",
        "\n",
        "def repackage_hidden(h):\n",
        "  \"\"\"은닉 상태를 변화도 기록에서 제거된 새로운 tensor로 만듭니다.\"\"\"\n",
        "\n",
        "  if isinstance(h, torch.Tensor):\n",
        "      return h.detach()\n",
        "  else:\n",
        "      return tuple(repackage_hidden(v) for v in h)\n",
        "\n",
        "def evaluate(model_, data_source):\n",
        "    # Dropout을 중지시키는 평가 모드로 실행합니다.\n",
        "    model_.eval()\n",
        "    total_loss = 0.\n",
        "    hidden = model_.init_hidden(eval_batch_size)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, data_source.size(0) - 1, bptt):\n",
        "            data, targets = get_batch(data_source, i)\n",
        "            output, hidden = model_(data, hidden)\n",
        "            hidden = repackage_hidden(hidden)\n",
        "            output_flat = output.view(-1, ntokens)\n",
        "            total_loss += len(data) * criterion(output_flat, targets).item()\n",
        "    return total_loss / (len(data_source) - 1)"
      ],
      "metadata": {
        "id": "RYlkjRhNnuJ4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 동적 양자화 테스트\n",
        "\n",
        "모델에서 동적 양자화를 호출하여 기존 모델과 비교해보았다.\n",
        "\n",
        "달라지는 부분 : 명시한 layer가 달라진다.\n",
        "- rnn(lstm) : LSTM -> DynamicQuantizedLSTM\n",
        "- decoder(linear) : LSTM -> DynamicQuantizedLSTM(..dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
        "\n",
        "Size(149->114), time(211->100)은 줄어들었고, loss는 같았다(근사하다).\n",
        "\n",
        "[quantize_dynamic docs](https://pytorch.org/docs/stable/generated/torch.quantization.quantize_dynamic.html)를 살펴보았다.\n",
        "\n",
        "1. float 모델을 동적(가중치만) 양자화된 모델로 변환한다.\n",
        "2. 특정 모듈(명시한 모듈)을 양자화 버전과 결과값을 가지는 양자화 모델로 대체한다.\n",
        "3. 가장 간단한 사용법은 float16을 qint8이 되도록 변형하는 것이다. 이것은 보통 가중치 크기가 큰 레이어에 대해 수행된다.\n",
        "4. 파라미터인 qconfig및 mapping으로 세밀한 제어도 가능하다."
      ],
      "metadata": {
        "id": "01kKBDm4y56i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.quantization\n",
        "\n",
        "quantized_model = torch.quantization.quantize_dynamic(\n",
        "    model, {nn.LSTM, nn.Linear}, dtype=torch.qint8\n",
        ")\n",
        "print(quantized_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPx961Czn9oO",
        "outputId": "5b0474d9-f8a0-496d-fd38-0773ce6d9580"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTMModel(\n",
            "  (drop): Dropout(p=0.5, inplace=False)\n",
            "  (encoder): Embedding(33278, 768)\n",
            "  (rnn): DynamicQuantizedLSTM(768, 256, num_layers=5, dropout=0.5)\n",
            "  (decoder): DynamicQuantizedLinear(in_features=256, out_features=33278, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzGiO8vAzDdP",
        "outputId": "c40c7c4e-5458-4186-b280-5ca3d4c06158"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTMModel(\n",
            "  (drop): Dropout(p=0.5, inplace=False)\n",
            "  (encoder): Embedding(33278, 768)\n",
            "  (rnn): LSTM(768, 256, num_layers=5, dropout=0.5)\n",
            "  (decoder): Linear(in_features=256, out_features=33278, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_size_of_model(model):\n",
        "    torch.save(model.state_dict(), \"temp.p\")\n",
        "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
        "    os.remove('temp.p')\n",
        "\n",
        "print_size_of_model(model)\n",
        "print_size_of_model(quantized_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_iAptf1n-oq",
        "outputId": "577871c2-9d4d-4cc4-df0d-79023004d020"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size (MB): 149.069856\n",
            "Size (MB): 114.07785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 메모: 양자화 된 모델은 단일 스레드로 실행되기 때문에 단일 스레드 비교를 위해\n",
        "# 스레드 수를 1로 설정했습니다.\n",
        "\n",
        "torch.set_num_threads(1)\n",
        "\n",
        "def time_model_evaluation(model, test_data):\n",
        "    s = time.time()\n",
        "    loss = evaluate(model, test_data)\n",
        "    elapsed = time.time() - s\n",
        "    print('''loss: {0:.3f}\\nelapsed time (seconds): {1:.1f}'''.format(loss, elapsed))\n",
        "\n",
        "time_model_evaluation(model, test_data)\n",
        "time_model_evaluation(quantized_model, test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHdU6Cwen_xE",
        "outputId": "ab20b91c-2457-4841-8490-18a90574f723"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 10.416\n",
            "elapsed time (seconds): 211.6\n",
            "loss: 10.416\n",
            "elapsed time (seconds): 100.9\n"
          ]
        }
      ]
    }
  ]
}